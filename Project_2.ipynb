{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rubic\n",
    "Grading Rubric\n",
    "* **Data Preparation (15** points total)\n",
    "    * **[10 points]** Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "    * **[5 points]** Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "* **Modeling and Evaluation** (70 points total)\n",
    "    * **[10 points]** Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up\n",
    "any assertions.\n",
    "    * **[10 points]** Choose the method you will use for dividing your data into training and testing splits\n",
    "(i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "    * **[20 points]** Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "    * **[10 points]** Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "    * **[10 points]** Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniquesâ€”be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "    * **[10 points]** Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "* **Deployment (5 points** total)\n",
    "    * **How useful is** your model for interested parties (i.e., the companies or organizations that might\n",
    "want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\n",
    "* **Exceptional Work (10** points total)\n",
    "    * **You have free** reign to provide additional analyses.\n",
    "    * **One idea:** grid search parameters in a parallelized fashion and visualize the performances across\n",
    "attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduciton\n",
    "Explanation of our data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation\n",
    "\n",
    "#### Pre Processing\n",
    "1. Set appropiate data types\n",
    "2. Removed columsn that may be problomatic\n",
    "    * Columns with same value in all rows\n",
    "    * Columsn with a unique value in all rows\n",
    "    * Empty Columns\n",
    "3. Remove columsn with low fill rate or high frequency of same value\n",
    "4. Missing contionus values are imputed using median value based on its Machine **Census_MDC2FormFactor**, i.e. *Notebook*, *Server*, *Tablet*, etc.\n",
    "5. Missing categorical values are imputed using the mode\n",
    "6. Remove Duplicate Rows\n",
    "7. Update datatypes to object for categorical values\n",
    "\n",
    "#### Feature Seleciton \\ Model Building\n",
    "1. Create One-Hot encoding on variables used for modeling\n",
    "2. Remove columsn with similar characterisitcs or a corrleation more than .95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.35 s, sys: 287 ms, total: 4.64 s\n",
      "Wall time: 3.51 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%run -i ColumnArrays.py\n",
    "\n",
    "%time malware = pd.read_csv(\"data/final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "### Mapping appropiate data types\n",
    "In order to understand the quality of the data, we did an extensive review of the data and determined which fields should be considered categorical, continous, or boolean.  We converted 23 id and category fields to object as well as removed outliers to make values boolean.  \n",
    "\n",
    "In order to help provide easier development, we created 4 array of column names: cols_booleans, cols_numerical, cols_categorical, and cols_categorical_large. The values with over 100 possible values were moved to its own bucket, cols_categorical_large, requiring special care to review in order to determine if we could cluster values together.\n",
    "\n",
    "The remaining code are steps we took to clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_booleans\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['IsBeta',\n",
       " 'IsSxsPassiveMode',\n",
       " 'HasTpm',\n",
       " 'IsProtected',\n",
       " 'AutoSampleOptIn',\n",
       " 'PuaMode',\n",
       " 'SMode',\n",
       " 'Firewall',\n",
       " 'UacLuaenable',\n",
       " 'Census_HasOpticalDiskDrive',\n",
       " 'Census_IsPortableOperatingSystem',\n",
       " 'Census_IsFlightingInternal',\n",
       " 'Census_IsFlightsDisabled',\n",
       " 'Census_ThresholdOptIn',\n",
       " 'Census_IsSecureBootEnabled',\n",
       " 'Census_IsWIMBootEnabled',\n",
       " 'Census_IsVirtualDevice',\n",
       " 'Census_IsTouchEnabled',\n",
       " 'Census_IsPenCapable',\n",
       " 'Census_IsAlwaysOnAlwaysConnectedCapable',\n",
       " 'Wdft_IsGamer']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_numerical\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Census_ProcessorCoreCount',\n",
       " 'Census_PrimaryDiskTotalCapacity',\n",
       " 'Census_SystemVolumeTotalCapacity',\n",
       " 'Census_TotalPhysicalRAM',\n",
       " 'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
       " 'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
       " 'Census_InternalPrimaryDisplayResolutionVertical',\n",
       " 'Census_InternalBatteryNumberOfCharges']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_categorical\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ProductName',\n",
       " 'EngineVersion',\n",
       " 'RtpStateBitfield',\n",
       " 'AVProductsInstalled',\n",
       " 'AVProductsEnabled',\n",
       " 'CountryIdentifier',\n",
       " 'OrganizationIdentifier',\n",
       " 'Platform',\n",
       " 'Processor',\n",
       " 'OsVer',\n",
       " 'OsBuild',\n",
       " 'OsSuite',\n",
       " 'OsPlatformSubRelease',\n",
       " 'SkuEdition',\n",
       " 'SmartScreen',\n",
       " 'Census_MDC2FormFactor',\n",
       " 'Census_DeviceFamily',\n",
       " 'Census_ProcessorManufacturerIdentifier',\n",
       " 'Census_ProcessorClass',\n",
       " 'Census_PrimaryDiskTypeName',\n",
       " 'Census_ChassisTypeName',\n",
       " 'Census_PowerPlatformRoleName',\n",
       " 'Census_InternalBatteryType',\n",
       " 'Census_OSArchitecture',\n",
       " 'Census_OSBranch',\n",
       " 'Census_OSBuildNumber',\n",
       " 'Census_OSEdition',\n",
       " 'Census_OSSkuName',\n",
       " 'Census_OSInstallTypeName',\n",
       " 'Census_OSInstallLanguageIdentifier',\n",
       " 'Census_OSUILocaleIdentifier',\n",
       " 'Census_OSWUAutoUpdateOptionsName',\n",
       " 'Census_GenuineStateName',\n",
       " 'Census_ActivationChannel',\n",
       " 'Census_FlightRing',\n",
       " 'Wdft_RegionIdentifier']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols_categorical_large\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AppVersion',\n",
       " 'AvSigVersion',\n",
       " 'DefaultBrowsersIdentifier',\n",
       " 'AVProductStatesIdentifier',\n",
       " 'CityIdentifier',\n",
       " 'GeoNameIdentifier',\n",
       " 'OsBuildLab',\n",
       " 'IeVerIdentifier',\n",
       " 'Census_OEMNameIdentifier',\n",
       " 'Census_OEMModelIdentifier',\n",
       " 'Census_ProcessorModelIdentifier',\n",
       " 'Census_OSVersion',\n",
       " 'Census_OSBuildRevision',\n",
       " 'Census_FirmwareManufacturerIdentifier',\n",
       " 'Census_FirmwareVersionIdentifier',\n",
       " 'LocaleEnglishNameIdentifier']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print( \"cols_booleans\" ) \n",
    "display( cols_booleans )\n",
    "print( \"cols_numerical\" )\n",
    "display( cols_numerical )\n",
    "print( \"cols_categorical\" )\n",
    "display( cols_categorical )\n",
    "print( \"cols_categorical_large\" )\n",
    "display( cols_categorical_large )\n",
    "\n",
    "#Convert features to right data type\n",
    "malware[cols_categorical] = malware[cols_categorical].astype(object)\n",
    "malware[cols_categorical_large] = malware[cols_categorical_large].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove problomatic columns\n",
    "* Columns with same value in all rows\n",
    "* Columsn with a unique value in all rows\n",
    "* Empty Columns\n",
    "\n",
    "We removed 3 fields that have either the same value or unique value in every row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following columns\n",
      " Index(['IsBeta', 'CountryIdentifier'], dtype='object')\n",
      "\n",
      "After: Removing columns with the same value in every row\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333411 entries, 0 to 333410\n",
      "Columns: 81 entries, MachineIdentifier to HasDetections\n",
      "dtypes: float64(19), int64(9), object(53)\n",
      "memory usage: 206.0+ MB\n",
      "\n",
      "Columns Deleted:  2\n",
      "Removing the following columns\n",
      " Index(['MachineIdentifier'], dtype='object')\n",
      "\n",
      "After: Removing columns with unique values in every row\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333411 entries, 0 to 333410\n",
      "Columns: 80 entries, ProductName to HasDetections\n",
      "dtypes: float64(19), int64(9), object(52)\n",
      "memory usage: 203.5+ MB\n",
      "\n",
      "Columns Deleted:  1\n",
      "Removing the following columns\n",
      " Index([], dtype='object')\n",
      "\n",
      "After: Removing columns with null / blank values in every row.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333411 entries, 0 to 333410\n",
      "Columns: 80 entries, ProductName to HasDetections\n",
      "dtypes: float64(19), int64(9), object(52)\n",
      "memory usage: 203.5+ MB\n",
      "\n",
      "Columns Deleted:  0\n"
     ]
    }
   ],
   "source": [
    "UniqueValueCounts = malware.nunique(dropna=False)\n",
    "SingleValueCols = UniqueValueCounts[UniqueValueCounts == 1].index\n",
    "malware = malware.drop(SingleValueCols, axis=1)\n",
    "\n",
    "#Review dataset contents after drops\n",
    "print( \"Removing the following columns\\n\", SingleValueCols )\n",
    "print( \"\\r\\nAfter: Removing columns with the same value in every row\" )\n",
    "malware.info(verbose=False)\n",
    "print('\\r\\nColumns Deleted: ', len(SingleValueCols) )\n",
    "\n",
    "#Remove any fields that have unique values in every row\n",
    "malwareRecordCt = malware.shape[0]\n",
    "UniqueValueCounts = malware.apply(pd.Series.nunique)\n",
    "AllUniqueValueCols = UniqueValueCounts[UniqueValueCounts == malwareRecordCt].index\n",
    "malware = malware.drop(AllUniqueValueCols, axis=1)\n",
    "\n",
    "#Review dataset contents after drops\n",
    "print( \"Removing the following columns\\n\", AllUniqueValueCols )\n",
    "print( \"\\r\\nAfter: Removing columns with unique values in every row\" )\n",
    "malware.info(verbose=False)\n",
    "print( \"\\r\\nColumns Deleted: \", len(AllUniqueValueCols) )\n",
    "\n",
    "#Remove any empty fields (null values in every row)\n",
    "malwareRecordCt = malware.shape[0]\n",
    "NullValueCounts = malware.isnull().sum()\n",
    "NullValueCols = NullValueCounts[NullValueCounts == malwareRecordCt].index\n",
    "malware = malware.drop(NullValueCols, axis=1)\n",
    "\n",
    "#Review dataset contents after empty field drops\n",
    "print( \"Removing the following columns\\n\", NullValueCols )\n",
    "print( \"\\r\\nAfter: Removing columns with null / blank values in every row.\" )\n",
    "malware.info(verbose=False)\n",
    "print( \"\\r\\nColumns Deleted: \", len(NullValueCols) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns with low fill-rate or high frequency of same value\n",
    "\n",
    "* Remove columsn with 60% of values are NA or NULL\n",
    "* Remove columsn with 80% of high frequency of same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing the following columns\n",
      " Index(['DefaultBrowsersIdentifier', 'PuaMode', 'Census_ProcessorClass',\n",
      "       'Census_InternalBatteryType', 'Census_IsFlightingInternal',\n",
      "       'Census_ThresholdOptIn', 'Census_IsWIMBootEnabled'],\n",
      "      dtype='object')\n",
      "\n",
      "After: Removing columns with >= .6 % of missing values\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333411 entries, 0 to 333410\n",
      "Columns: 73 entries, ProductName to HasDetections\n",
      "dtypes: float64(16), int64(9), object(48)\n",
      "memory usage: 185.7+ MB\n",
      "\n",
      "Columns Deleted:  7\n",
      "Removing the following columns\n",
      " Index(['ProductName', 'RtpStateBitfield', 'IsSxsPassiveMode',\n",
      "       'AVProductsEnabled', 'HasTpm', 'GeoNameIdentifier',\n",
      "       'LocaleEnglishNameIdentifier', 'Platform', 'Processor', 'OsVer',\n",
      "       'IsProtected', 'AutoSampleOptIn', 'SMode', 'Firewall', 'UacLuaenable',\n",
      "       'Census_DeviceFamily', 'Census_HasOpticalDiskDrive',\n",
      "       'Census_OSArchitecture', 'Census_IsPortableOperatingSystem',\n",
      "       'Census_GenuineStateName', 'Census_IsFlightsDisabled',\n",
      "       'Census_FlightRing', 'Census_IsVirtualDevice', 'Census_IsTouchEnabled',\n",
      "       'Census_IsPenCapable', 'Census_IsAlwaysOnAlwaysConnectedCapable',\n",
      "       'Wdft_RegionIdentifier'],\n",
      "      dtype='object')\n",
      "\n",
      "After: Removing columns with >= .8 % of missing values\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 333411 entries, 0 to 333410\n",
      "Columns: 46 entries, EngineVersion to HasDetections\n",
      "dtypes: float64(9), int64(2), object(35)\n",
      "memory usage: 117.0+ MB\n",
      "\n",
      "Columns Deleted:  27\n"
     ]
    }
   ],
   "source": [
    "#Eliminate columns with 80% of missing values\n",
    "malwareRecordCt = malware.shape[0]\n",
    "missingValueLimit = malwareRecordCt * .6\n",
    "NullValueCounts = malware.isnull().sum()\n",
    "NullValueCols = NullValueCounts[NullValueCounts >= missingValueLimit].index\n",
    "malware = malware.drop(NullValueCols, axis=1)\n",
    "\n",
    "#Review dataset contents after empty field drops\n",
    "print( \"Removing the following columns\\n\", NullValueCols )\n",
    "print( \"\\r\\nAfter: Removing columns with >= .6 % of missing values\" )\n",
    "malware.info(verbose=False)\n",
    "print (\"\\r\\nColumns Deleted: \", len(NullValueCols) )\n",
    "\n",
    "#Eliminate values with 80% of the value is the same\n",
    "malwareRecordCt = malware.shape[0]\n",
    "sameValueLimit = malwareRecordCt * .8\n",
    "MaxColumnFreq = malware.apply(lambda x: x.value_counts().values[0])\n",
    "HighFreqCols = MaxColumnFreq[MaxColumnFreq >= sameValueLimit].index\n",
    "malware = malware.drop(HighFreqCols, axis=1)\n",
    "\n",
    "#Review dataset contents after high frequency delete\n",
    "print( \"Removing the following columns\\n\", HighFreqCols )\n",
    "print( \"\\r\\nAfter: Removing columns with >= .8 % of missing values\" )\n",
    "malware.info(verbose=False)\n",
    "print (\"\\r\\nColumns Deleted: \", len(HighFreqCols) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update our column arrays\n",
    "cols_categorical = [x for x in cols_categorical if x in malware.columns]\n",
    "cols_numerical = [x for x in cols_numerical if x in malware.columns]\n",
    "cols_booleans = [x for x in cols_booleans if x in malware.columns]\n",
    "cols_categorical_large = [x for x in cols_categorical_large if x in malware.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Missing Values\n",
    "### Census Hardware Configurations\n",
    "The continuous values represent all of hardware configurations on a machine, for example memory and hard drive capacity.  In order to assign the right value, we will use the median value grouped by **Census_MDC2FormFactor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: Updating Missing Continous Values\n",
      "Rows Updated / Imputed:  14431\n",
      "\r\n",
      "Total Rows Missing Census Hardware by Census_MDC2FormFactor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Series([], Name: Census_MDC2FormFactor, dtype: int64)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the median value for each field\n",
    "rowsBefore = malware[cols_numerical].isnull().T.any().T.sum()\n",
    "\n",
    "#Removing values less then 0\n",
    "malware[cols_numerical] = malware[cols_numerical].replace(-1, np.nan)\n",
    "\n",
    "malware[cols_numerical] = malware.groupby(\"Census_MDC2FormFactor\")[cols_numerical]\\\n",
    "    .transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "#Review dataset contents after Census_MDC2FormFactor Census hardware Imputation\n",
    "print(\"After: Updating Missing Continous Values\")   \n",
    "rowsAfter = malware[cols_numerical].isnull().T.any().T.sum()\n",
    "rowsUpdated = rowsBefore - rowsAfter\n",
    "print('Rows Updated / Imputed: ', rowsUpdated )\n",
    "print('\\r\\nTotal Rows Missing Census Hardware by Census_MDC2FormFactor') \n",
    "malware['Census_MDC2FormFactor'][malware[cols_numerical].isnull().T.any().T].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Categorial Configurations\n",
    "Assign remaining missing values associated to Census details based on the mode of **Census_MDC2FormFactor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: Updating Missing Continous Values\n",
      "Rows Updated / Imputed:  9458\n",
      "\n",
      "Total Rows Missing for Census Fields:  0\n"
     ]
    }
   ],
   "source": [
    "#Get all census fields\n",
    "CensusFields = malware.filter(regex='Census').columns\n",
    "NullValueCounts = malware[CensusFields].isnull().sum()\n",
    "NullValueCols = NullValueCounts[NullValueCounts > 0 ].index\n",
    "\n",
    "rowsBefore = malware[NullValueCols].isnull().T.any().T.sum()\n",
    "\n",
    "#Group by FormFactor and OSSkuName\n",
    "malware[NullValueCols] = malware.groupby([\"Census_MDC2FormFactor\"])[NullValueCols]\\\n",
    "    .transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "#Review dataset contents after Census Mode Imputations\n",
    "print(\"After: Updating Missing Continous Values\")   \n",
    "rowsAfter = malware[NullValueCols].isnull().T.any().T.sum()\n",
    "rowsUpdated = rowsBefore - rowsAfter\n",
    "print('Rows Updated / Imputed: ', rowsUpdated )\n",
    "print('\\r\\nTotal Rows Missing for Census Fields: ',malware[CensusFields].isnull().T.any().T.sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining Features\n",
    "Set the remaining features as 0, to indicate not turned on (boolean) or feature available (categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: Updating Missing Values\n",
      "Rows Updated / Imputed:  120472\n",
      "\n",
      "Total Rows Missing values:  0\n"
     ]
    }
   ],
   "source": [
    "NullValueCounts = malware.isnull().sum()\n",
    "NullValueCols = NullValueCounts[NullValueCounts > 0 ].index\n",
    "\n",
    "rowsBefore = malware[NullValueCols].isnull().T.any().T.sum()\n",
    "\n",
    "malware[NullValueCols] = malware[NullValueCols].fillna(0)\n",
    "\n",
    "#Review dataset contents after Census Mode Imputations\n",
    "print(\"After: Updating Missing Values\")   \n",
    "rowsAfter = malware[NullValueCols].isnull().T.any().T.sum()\n",
    "rowsUpdated = rowsBefore - rowsAfter\n",
    "print('Rows Updated / Imputed: ', rowsUpdated )\n",
    "print('\\r\\nTotal Rows Missing values: ',malware.isnull().T.any().T.sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart Screen fill miising values and fix characters issue\n",
    "malware.SmartScreen.replace({\"off\":\"Off\",\"00000000\":\"ExistsNotSet\",\"&#x02;\" :\"ExistsNotSet\",\n",
    "                                 \"&#x01;\" :\"ExistsNotSet\",\"0\":\"ExistsNotSet\"},inplace=True)\n",
    "# currently renamed \"Census_PrimaryDiskTypeName\" unknown data into one category\n",
    "malware.Census_PrimaryDiskTypeName.replace({\"Unspecified\":\"Other\"},inplace=True)\n",
    "\n",
    "# currently renamed \"Census_ChassisTypeName\" unknown data into one category\n",
    "malware.Census_ChassisTypeName.replace({\"UNKNOWN\":\"Other\",\"Unknown\":\"Other\",\"0\" :\"Other\",\n",
    "                                \"30\" :\"Other\",\n",
    "                                \"35\" :\"Other\",\n",
    "                                \"112\" :\"Other\",\n",
    "                                \"76\" :\"Other\",\n",
    "                                \"39\" :\"Other\"},inplace=True)\n",
    "\n",
    "# currently renamed \"Census_PowerPlatformRoleName\" unknown data into one category\n",
    "\n",
    "malware.Census_PowerPlatformRoleName.fillna('Other', inplace=True)\n",
    "\n",
    "malware.Census_PowerPlatformRoleName.replace({\"UNKNOWN\":\"Other\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After: Deleting rows\n",
      "Rows removed:  486\n"
     ]
    }
   ],
   "source": [
    "rowsBefore = len(malware)\n",
    "malware = malware.drop_duplicates()\n",
    "\n",
    "\n",
    "#Review dataset after deleting duplicates\n",
    "print(\"After: Deleting rows\")   \n",
    "rowsAfter = len(malware)\n",
    "rowsUpdated = rowsBefore - rowsAfter\n",
    "print('Rows removed: ', rowsUpdated )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection \\ Model Building\n",
    "Following functions are used during model building\n",
    "* Create Hot=One Encoding\n",
    "* Remove Highly Corrleated Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_hot_encodings(df, cols):\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reduce_features(df, verbose = False):\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
