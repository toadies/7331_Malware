{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 7331 Data Mining\n",
    "### Logistic Regression and SVM\n",
    "### Mini Lab\n",
    "* Tahir Ahmad<br>\n",
    "* Christopher Ballenger<br>\n",
    "* Grant Bourzikas<br>\n",
    "* Vitaly Briker<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 7331 Data Mining\n",
    "### Logistic Regression and SVM\n",
    "### Mini Lab\n",
    "* Tahir Ahmad<br>\n",
    "* Christopher Ballenger<br>\n",
    "* Grant Bourzikas<br>\n",
    "* Vitaly Briker<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning\n",
    "\n",
    "#Show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "%run -i ColumnArrays.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.6 s, sys: 359 ms, total: 4.96 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%time final = pd.read_csv(\"data/clean.final.csv\")\n",
    "\n",
    "final[cols_categorical] = final[cols_categorical].astype(object)\n",
    "final[cols_categorical_large] = final[cols_categorical_large].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333411, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Response = final[[\"HasDetections\", \"MachineIdentifier\"]]\n",
    "display(Response.shape)\n",
    "\n",
    "EngineVersion = pd.get_dummies(final[\"EngineVersion\"],prefix=\"EngineVersion\")\n",
    "RtpStateBitfield = pd.get_dummies(final[\"RtpStateBitfield\"],prefix=\"RtpStateBitfield\")\n",
    "AVProductsInstalled = pd.get_dummies(final[\"AVProductsInstalled\"],prefix=\"AVProductsInstalled\")\n",
    "AVProductsEnabled = pd.get_dummies(final[\"AVProductsEnabled\"],prefix=\"AVProductsEnabled\")\n",
    "OrganizationIdentifier = pd.get_dummies(final[\"OrganizationIdentifier\"],prefix=\"OrganizationIdentifier\")\n",
    "Platform = pd.get_dummies(final[\"Platform\"],prefix=\"Platform\")\n",
    "Processor = pd.get_dummies(final[\"Processor\"],prefix=\"Processor\")\n",
    "OsVer = pd.get_dummies(final[\"OsVer\"],prefix=\"OsVer\")\n",
    "OsBuild = pd.get_dummies(final[\"OsBuild\"],prefix=\"OsBuild\")\n",
    "OsSuite = pd.get_dummies(final[\"OsSuite\"],prefix=\"OsSuite\")\n",
    "OsPlatformSubRelease = pd.get_dummies(final[\"OsPlatformSubRelease\"],prefix=\"OsPlatformSubRelease\")\n",
    "SkuEdition = pd.get_dummies(final[\"SkuEdition\"],prefix=\"SkuEdition\")\n",
    "SmartScreen = pd.get_dummies(final[\"SmartScreen\"],prefix=\"SmartScreen\")\n",
    "Census_MDC2FormFactor = pd.get_dummies(final[\"Census_MDC2FormFactor\"],prefix=\"Census_MDC2FormFactor\")\n",
    "Census_ProcessorManufacturerIdentifier = pd.get_dummies(final[\"Census_ProcessorManufacturerIdentifier\"],prefix=\"Census_ProcessorManufacturerIdentifier\")\n",
    "Census_PrimaryDiskTypeName = pd.get_dummies(final[\"Census_PrimaryDiskTypeName\"],prefix=\"Census_PrimaryDiskTypeName\")\n",
    "Census_ChassisTypeName = pd.get_dummies(final[\"Census_ChassisTypeName\"],prefix=\"Census_ChassisTypeName\")\n",
    "Census_PowerPlatformRoleName = pd.get_dummies(final[\"Census_PowerPlatformRoleName\"],prefix=\"Census_PowerPlatformRoleName\")\n",
    "Census_OSArchitecture = pd.get_dummies(final[\"Census_OSArchitecture\"],prefix=\"Census_OSArchitecture\")\n",
    "Census_OSBranch = pd.get_dummies(final[\"Census_OSBranch\"],prefix=\"Census_OSBranch\")\n",
    "Census_OSBuildNumber = pd.get_dummies(final[\"Census_OSBuildNumber\"],prefix=\"Census_OSBuildNumber\")\n",
    "Census_OSEdition = pd.get_dummies(final[\"Census_OSEdition\"],prefix=\"Census_OSEdition\")\n",
    "Census_OSSkuName = pd.get_dummies(final[\"Census_OSSkuName\"],prefix=\"Census_OSSkuName\")\n",
    "Census_OSInstallTypeName = pd.get_dummies(final[\"Census_OSInstallTypeName\"],prefix=\"Census_OSInstallTypeName\")\n",
    "Census_OSInstallLanguageIdentifier = pd.get_dummies(final[\"Census_OSInstallLanguageIdentifier\"],prefix=\"Census_OSInstallLanguageIdentifier\")\n",
    "Census_OSUILocaleIdentifier = pd.get_dummies(final[\"Census_OSUILocaleIdentifier\"],prefix=\"Census_OSUILocaleIdentifier\")\n",
    "Census_OSWUAutoUpdateOptionsName = pd.get_dummies(final[\"Census_OSWUAutoUpdateOptionsName\"],prefix=\"Census_OSWUAutoUpdateOptionsName\")\n",
    "Census_GenuineStateName = pd.get_dummies(final[\"Census_GenuineStateName\"],prefix=\"Census_GenuineStateName\")\n",
    "Census_ActivationChannel = pd.get_dummies(final[\"Census_ActivationChannel\"],prefix=\"Census_ActivationChannel\")\n",
    "Census_FlightRing = pd.get_dummies(final[\"Census_FlightRing\"],prefix=\"Census_FlightRing\")\n",
    "Wdft_RegionIdentifier = pd.get_dummies(final[\"Wdft_RegionIdentifier\"],prefix=\"Wdft_RegionIdentifier\")\n",
    "\n",
    "final[\"SmartScreenOn\"] = final.SmartScreen\n",
    "final.SmartScreenOn.replace(\n",
    "    {\n",
    "        \"Block\":\"Enable\",\n",
    "        \"ExistsNotSet\":\"Disable\",\n",
    "        \"Off\" :\"Disable\",\n",
    "        \"Prompt\" :\"Enable\",\n",
    "        \"RequireAdmin\":\"Enable\",\n",
    "        \"Warn\":\"Enable\"\n",
    "    },inplace=True)\n",
    "\n",
    "AppVersion = pd.get_dummies(final[\"AppVersion\"],prefix=\"AppVersion\")\n",
    "AvSigVersion = pd.get_dummies(final[\"AvSigVersion\"],prefix=\"AvSigVersion\")\n",
    "AVProductStatesIdentifier  = pd.get_dummies(final[\"AVProductStatesIdentifier\"],prefix=\"AVProductStatesIdentifier\")\n",
    "\n",
    "AppVersion_split = final[\"AppVersion\"].str.rsplit(pat=\".\",expand=True)\n",
    "final[\"AppVersion_x_x\"] = AppVersion_split.loc[:,0]+\".\"+AppVersion_split.loc[:,1]#+\".\"+AppVersion_split.loc[:,2]\n",
    "\n",
    "AvSigVersion_split = final[\"AvSigVersion\"].str.rsplit(pat=\".\",expand=True)\n",
    "final[\"AvSigVersion_x_x\"] = AvSigVersion_split.loc[:,0]+\".\"+AvSigVersion_split.loc[:,1]\n",
    "final[\"AvSigVersion_x_x_x\"] = AvSigVersion_split.loc[:,0]+\".\"+AvSigVersion_split.loc[:,1]+\".\"+AvSigVersion_split.loc[:,2].str[:2]\n",
    "\n",
    "AppVersion_x_x = pd.get_dummies(final[\"AppVersion_x_x\"],prefix=\"AppVersion_x_x\")\n",
    "AvSigVersion_x_x = pd.get_dummies(final[\"AvSigVersion_x_x\"],prefix=\"AvSigVersion_x_x\")\n",
    "AvSigVersion_x_x_x  = pd.get_dummies(final[\"AvSigVersion_x_x_x\"],prefix=\"AvSigVersion_x_x_x\")\n",
    "\n",
    "\n",
    "                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    (\n",
    "        EngineVersion,\n",
    "        AvSigVersion_x_x,\n",
    "        AppVersion_x_x\n",
    "    ), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.concat(\n",
    "    (\n",
    "        AVProductStatesIdentifier,\n",
    "        AVProductsInstalled,\n",
    "        SmartScreen,\n",
    "        AvSigVersion_x_x,\n",
    "        AppVersion_x_x\n",
    "    ),axis=1)\n",
    "\n",
    "# final[[\"IsProtected\",\"Firewall\"]],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Setup \n",
    "# Loads Finalized Data Set\n",
    "\n",
    "# Get DF1\n",
    "df1 = pd.concat(\n",
    "    (\n",
    "        df,\n",
    "        Census_MDC2FormFactor,\n",
    "        Census_OSSkuName,\n",
    "        Census_GenuineStateName,\n",
    "        Census_ActivationChannel\n",
    "    ),axis=1)\n",
    "\n",
    "df_continous = final[cols_numerical].copy()\n",
    "df_continous[\"Census_SystemVolumeTotalCapacity\"] = np.log(df_continous.Census_SystemVolumeTotalCapacity)\n",
    "df_continous[\"Census_TotalPhysicalRAM\"] = np.log(df_continous.Census_TotalPhysicalRAM)\n",
    "df_continous[\"Census_PrimaryDiskTotalCapacity\"] = np.log(df_continous.Census_PrimaryDiskTotalCapacity)\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df1.values\n",
    "x2 = df_continous.values\n",
    "y = final[\"HasDetections\"].values\n",
    "\n",
    "X = np.append(x1,x2,axis=1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose and explain your evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in determining what metrics should be used, is to outline the challenge the data will present.  Since this is a binary classification problem, each model will be assessed to determin the eficacy the models.  There are three key types of metrics that will be used: ROC Curves, Confusion Matrices, and statistcs:\n",
    "\n",
    "* <u>ROC Curves</u> - Each model that is assessed will have a a grpahical represntation of the ROC curve and AUC.  Additionally, all models will be aggregated and presented individually to compare against each other.\n",
    "* <u>Confusion Matrices</u> - Each model will have a final confusion matrix that will be presented.  While we will be concerned with the accuracy of True Postivies and True Negatives, Type 1 error (False Postives) and Type 2 error (False Negatives) will be analyzed.  Type 2 Error, False Negatives, are systems that did get compromised that were missed in the model. While Type 1 error of Fales Postives are important, this can often led to a resource waste in attempting to remedate malware in which no malware is presented. Additionaly, precision, recall, and the F1 Measurement will be analzyed.  Because there will be weak learners, boosting will be used to ensure the difficult learners will be captured.\n",
    "* <u>Model Comparision</u> As models are analzyed, we will compare the models to determine the differences between inccorrect and correct predictions between Model 1 and Model 2.  This is a very similiar matrix as the confusion matrix, but this will allow a model comparision.  The goals is to have a great number in the statistics that Model 1 and 2 are correct  and incoorect together as compared to discrepncy between both model predictions.\n",
    "* <u>Statistifcs</u> Each model will additinaly analzyed to determine RMSE, R2, and MSE as an additional check and validation of the ROC Curves and Confusion Matrices\n",
    "* <u>Clustering</u> - For each cluster, the team will review elbow charts to determine the optimal number of clusters for k-means clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose and explain your testing splits (10 Points) – Friday February 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a best practice, we attempted to a cross validation of 10 but because of the size of the data set, we were not able complete the analysis of the models due to compute resources.  Instead, we will perform a 10% sample on our data set and use a cross validation of 3.  We will leave one set out to ensure there are different training sets and different tests to validate the model.  Additionally, we will measure the Cross Valuation Score in SKLearn, cross_val_score, to ensure the dataset is balanced and the models generate statistically valid results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale dataset converting to standard normally distributed data \n",
    "# (e.g. Gaussian with 0 mean and unit variance).\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit to data for scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform training data to z-scores\n",
    "# This makes our model's coefficients take on the same scale for accurate feature importance analisys \n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual != 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Baseline Regressoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 17.2 µs\n",
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#Create a Linear regression object and perform a grid search to find the best parameters\n",
    "from sklearn.svm import SVR\n",
    "reg = SVR()\n",
    "\n",
    "#Set up SVR parameters to test (WARNING: Creates 320 models!!!) \n",
    "costs = [0.001, 0.1, 10]\n",
    "defGamma = 1 / X_train.shape[1]  #This is the default value for the gamma parameter\n",
    "gammas = [defGamma, 0.1, 1]\n",
    "kernels = ['rbf','linear']\n",
    "parameters = {'C': costs, 'gamma' : gammas, 'kernel': kernels}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
    "                      kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
    "                      kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "regEstimator.fit(X, y)\n",
    "yhat = regEstimator.predict(X)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "reg = Lasso(fit_intercept=True, normalize=True,copy_X=True\n",
    "          , max_iter=10000, precompute=True, tol=0.0001, random_state=0)\n",
    "\n",
    "#Test parameters \n",
    "alpha = [0.001, 0.1, 1, 10, 20]\n",
    "selection = ['cyclic','random']\n",
    "warm_start = [True, False]\n",
    "parameters = {'alpha': alpha, 'selection': selection, 'warm_start': warm_start}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=reg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
    "   normalize=True, positive=False, precompute=True, random_state=0,\n",
    "   selection='cyclic', tol=0.0001, warm_start=True)\n",
    "\n",
    "regEstimator.fit(X, y)\n",
    "yhat = regEstimator.predict(X)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "linreg = RandomForestRegressor()\n",
    "parameters = { 'min_samples_split':[2,3,4,5]\n",
    "              ,'n_estimators' : [500]\n",
    "              ,'min_samples_leaf': [10, 25, 50]\n",
    "              ,'criterion': ['mae']\n",
    "              ,'n_jobs':[8] \n",
    "              ,'random_state': [0]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , n_jobs=8 \n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%time\n",
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "regEstimator.fit(X, y)\n",
    "yhat = regEstimator.predict(X)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "linreg = ExtraTreesRegressor()\n",
    "parameters = { 'min_samples_split':[2,3,4,5]\n",
    "              ,'n_estimators' : [500]\n",
    "              ,'min_samples_leaf': [10, 25, 50]\n",
    "              ,'criterion': ['mae']\n",
    "              ,'n_jobs':[8] \n",
    "              ,'random_state': [0]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Do we predict graduation rates greater than 100%?\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "regEstimator.fit(X, y)\n",
    "yhat = regEstimator.predict(X)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "linreg = MLPRegressor()\n",
    "parameters = { 'activation':['logistic']\n",
    "              ,'hidden_layer_sizes' : [200]\n",
    "              ,'solver': ['sgd','adam']\n",
    "              ,'alpha': [0.001]\n",
    "              ,'batch_size':['auto'] \n",
    "              ,'random_state': [0]\n",
    "              ,'learning_rate': ['constant', 'invscaling', 'adaptive']\n",
    "              ,'learning_rate_init':[0.001]\n",
    "              ,'power_t':[0.5]\n",
    "              ,'max_iter':[1000]\n",
    "             }\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
    "                                       max_features='auto', max_leaf_nodes=None,\n",
    "                                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                                       min_samples_leaf=10, min_samples_split=2,\n",
    "                                       min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=8,\n",
    "                                       oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "#Fit the model using all of the scaled training data\n",
    "regEstimator.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#Load the model's coefficient weights and feature names into a dataframe sorted by weights\n",
    "weights = regEstimator.feature_importances_.ravel()\n",
    "feature_names = X.columns.values\n",
    "linreg_ft_imp_df = pd.DataFrame({'feature_names':feature_names, 'weights':weights, 'absolute_weights': np.abs(weights)})\n",
    "linreg_ft_imp_df.sort_values(by='absolute_weights', inplace=True, ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Examine categorical variables of interest  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Plot the model's feature importances\n",
    "# REFERENCE:  Eric Larson, https://github.com/eclarson/DataMiningNotebooks\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "wt_plt_df = linreg_ft_imp_df.head(75)\n",
    "\n",
    "weights = pd.Series(wt_plt_df['weights'].values,index=wt_plt_df['feature_names'])\n",
    "ax = weights.plot(kind='bar', figsize=(20,8))\n",
    "\n",
    "ax.set_title(\"Top Feature Correlations\")\n",
    "ax.set_ylabel(\"Coefficient Magnitude\\n(z-score)\")\n",
    "ax.set_xlabel(\"Feature Names\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
