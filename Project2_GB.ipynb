{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_column_array(cols):\n",
    "    cols_booleans = [\n",
    "        \"IsBeta\",\n",
    "        \"IsSxsPassiveMode\",\n",
    "        \"HasTpm\",\n",
    "        \"IsProtected\",\n",
    "        \"AutoSampleOptIn\",\n",
    "        \"PuaMode\",\n",
    "        \"SMode\",\n",
    "        \"Firewall\",\n",
    "        \"UacLuaenable\",\n",
    "        \"Census_HasOpticalDiskDrive\",\n",
    "        \"Census_IsPortableOperatingSystem\",\n",
    "        \"Census_IsFlightingInternal\",\n",
    "        \"Census_IsFlightsDisabled\",\n",
    "        \"Census_ThresholdOptIn\",\n",
    "        \"Census_IsSecureBootEnabled\",\n",
    "        \"Census_IsWIMBootEnabled\",\n",
    "        \"Census_IsVirtualDevice\",\n",
    "        \"Census_IsTouchEnabled\",\n",
    "        \"Census_IsPenCapable\",\n",
    "        \"Census_IsAlwaysOnAlwaysConnectedCapable\",\n",
    "        \"Wdft_IsGamer\"\n",
    "    ]\n",
    "\n",
    "    cols_categorical = [\n",
    "        \"ProductName\",\n",
    "        \"EngineVersion\",\n",
    "        \"AppVersion\",\n",
    "        \"AvSigVersion_x_x\",\n",
    "        \"RtpStateBitfield\",\n",
    "        \"AVProductsInstalled\",\n",
    "        \"AVProductsEnabled\",\n",
    "        \"CountryIdentifier\",\n",
    "        \"OrganizationIdentifier\",\n",
    "        \"Platform\",\n",
    "        \"Processor\",\n",
    "        \"OsVer\",\n",
    "        \"OsBuild\",\n",
    "        \"OsSuite\",\n",
    "        \"OsPlatformSubRelease\",\n",
    "        \"SkuEdition\",\n",
    "        \"SmartScreen\",\n",
    "        \"Census_MDC2FormFactor\",\n",
    "        \"Census_DeviceFamily\",\n",
    "        \"Census_ProcessorManufacturerIdentifier\",\n",
    "        \"Census_ProcessorClass\",\n",
    "        \"Census_PrimaryDiskTypeName\",\n",
    "        \"Census_ChassisTypeName\",\n",
    "        \"Census_PowerPlatformRoleName\",\n",
    "        \"Census_InternalBatteryType\",\n",
    "        \"Census_OSArchitecture\",\n",
    "        \"Census_OSBranch\",\n",
    "        \"Census_OSBuildNumber\",\n",
    "        \"Census_OSEdition\",\n",
    "        \"Census_OSSkuName\",\n",
    "        \"Census_OSInstallTypeName\",\n",
    "        \"Census_OSInstallLanguageIdentifier\",\n",
    "        \"Census_OSUILocaleIdentifier\",\n",
    "        \"Census_OSWUAutoUpdateOptionsName\",\n",
    "        \"Census_GenuineStateName\",\n",
    "        \"Census_ActivationChannel\",\n",
    "        \"Census_FlightRing\",\n",
    "        \"Wdft_RegionIdentifier\"\n",
    "    ]\n",
    "\n",
    "    cols_categorical_large = [\n",
    "        \"AvSigVersion\",\n",
    "        \"DefaultBrowsersIdentifier\",\n",
    "        \"AVProductStatesIdentifier\",\n",
    "        \"CityIdentifier\",\n",
    "        \"GeoNameIdentifier\",\n",
    "        \"OsBuildLab\",\n",
    "        \"IeVerIdentifier\",\n",
    "        \"Census_OEMNameIdentifier\",\n",
    "        \"Census_OEMModelIdentifier\",\n",
    "        \"Census_ProcessorModelIdentifier\",\n",
    "        \"Census_OSVersion\",\n",
    "        \"Census_OSBuildRevision\",\n",
    "        \"Census_FirmwareManufacturerIdentifier\",\n",
    "        \"Census_FirmwareVersionIdentifier\",\n",
    "        \"LocaleEnglishNameIdentifier\"\n",
    "    ]\n",
    "\n",
    "    cols_numerical = [\n",
    "        \"Census_ProcessorCoreCount\",\n",
    "        \"Census_PrimaryDiskTotalCapacity\",\n",
    "        \"Census_SystemVolumeTotalCapacity\",\n",
    "        \"Census_TotalPhysicalRAM\",\n",
    "        \"Census_InternalPrimaryDiagonalDisplaySizeInInches\",\n",
    "        \"Census_InternalPrimaryDisplayResolutionHorizontal\",\n",
    "        \"Census_InternalPrimaryDisplayResolutionVertical\",\n",
    "        \"Census_InternalBatteryNumberOfCharges\"\n",
    "    ]\n",
    "    \n",
    "    # Update our column arrays\n",
    "    cols_categorical = [x for x in cols_categorical if x in cols]\n",
    "    cols_numerical = [x for x in cols_numerical if x in cols]\n",
    "    cols_booleans = [x for x in cols_booleans if x in cols]\n",
    "    cols_categorical_large = [x for x in cols_categorical_large if x in cols]\n",
    "    \n",
    "    return cols_categorical, cols_numerical, cols_booleans, cols_categorical_large\n",
    "\n",
    "def get_one_hot_encodings(df, cols):\n",
    "    result = pd.DataFrame()\n",
    "    i = 0\n",
    "    for col in cols:\n",
    "        dummies = pd.get_dummies(df[col],prefix=col)\n",
    "        if( i == 0 ):\n",
    "            result = dummies.copy()\n",
    "        else:\n",
    "            result = pd.concat((result, dummies), axis=1)\n",
    "        i+=1\n",
    "    return result\n",
    "\n",
    "def reduce_features(df, verbose = False):\n",
    "    # calculate the correlation matrix\n",
    "    corr_matrix  = df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    \n",
    "    #Get all of the correlation values > 95%\n",
    "    x = np.where(upper > 0.95)\n",
    "\n",
    "    #Display all field combinations with > 95% correlation\n",
    "    cf = pd.DataFrame()\n",
    "    cf['Field1'] = upper.columns[x[1]]\n",
    "    cf['Field2'] = upper.index[x[0]]\n",
    "\n",
    "    #Get the correlation values for every field combination. (There must be a more pythonic way to do this!)\n",
    "    corr = [0] * len(cf)\n",
    "    for i in range(0, len(cf)):\n",
    "        corr[i] =  upper[cf['Field1'][i]][cf['Field2'][i]] \n",
    "\n",
    "    cf['Correlation'] = corr\n",
    "\n",
    "    if( verbose ):\n",
    "        print('There are ', str(len(cf['Field1'])), ' field correlations > 95%.')\n",
    "        display(cf)\n",
    "        \n",
    "        print('Dropping the following ', str(len(to_drop)), ' highly correlated fields.')\n",
    "        to_drop\n",
    "        \n",
    "    #Check columns before drop \n",
    "    if( verbose ):\n",
    "        print('\\r\\n*********Before: Dropping Highly Correlated Fields*************************************')\n",
    "        display(df.info(verbose=False))\n",
    "\n",
    "    # Drop the highly correlated features from our training data \n",
    "    df = df.drop(to_drop, axis=1)\n",
    "\n",
    "    #Check columns after drop \n",
    "    if( verbose ):\n",
    "        print('\\r\\n*********After: Dropping Highly Correlated Fields**************************************')\n",
    "        df.info(verbose=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  115  field correlations > 95%.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field1</th>\n",
       "      <th>Field2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AvSigVersion_x_x_1.199</td>\n",
       "      <td>EngineVersion_1.1.11701.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AvSigVersion_x_x_1.203</td>\n",
       "      <td>EngineVersion_1.1.11903.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AvSigVersion_x_x_1.207</td>\n",
       "      <td>EngineVersion_1.1.12101.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AvSigVersion_x_x_1.225</td>\n",
       "      <td>EngineVersion_1.1.12902.0</td>\n",
       "      <td>0.970322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AvSigVersion_x_x_1.227</td>\n",
       "      <td>EngineVersion_1.1.13000.0</td>\n",
       "      <td>0.969724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AvSigVersion_x_x_1.229</td>\n",
       "      <td>EngineVersion_1.1.13103.0</td>\n",
       "      <td>0.990140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AvSigVersion_x_x_1.2309999999999999</td>\n",
       "      <td>EngineVersion_1.1.13202.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AvSigVersion_x_x_1.2329999999999999</td>\n",
       "      <td>EngineVersion_1.1.13303.0</td>\n",
       "      <td>0.994483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AvSigVersion_x_x_1.235</td>\n",
       "      <td>EngineVersion_1.1.13407.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AvSigVersion_x_x_1.237</td>\n",
       "      <td>EngineVersion_1.1.13504.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AvSigVersion_x_x_1.239</td>\n",
       "      <td>EngineVersion_1.1.13601.0</td>\n",
       "      <td>0.992149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AvSigVersion_x_x_1.2409999999999999</td>\n",
       "      <td>EngineVersion_1.1.13701.0</td>\n",
       "      <td>0.989063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AvSigVersion_x_x_1.2429999999999999</td>\n",
       "      <td>EngineVersion_1.1.13704.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AvSigVersion_x_x_1.245</td>\n",
       "      <td>EngineVersion_1.1.13804.0</td>\n",
       "      <td>0.987246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AvSigVersion_x_x_1.247</td>\n",
       "      <td>EngineVersion_1.1.13903.0</td>\n",
       "      <td>0.994229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AvSigVersion_x_x_1.249</td>\n",
       "      <td>EngineVersion_1.1.14003.0</td>\n",
       "      <td>0.993831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AvSigVersion_x_x_1.251</td>\n",
       "      <td>EngineVersion_1.1.14104.0</td>\n",
       "      <td>0.996961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AvSigVersion_x_x_1.253</td>\n",
       "      <td>EngineVersion_1.1.14202.0</td>\n",
       "      <td>0.980109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AvSigVersion_x_x_1.255</td>\n",
       "      <td>EngineVersion_1.1.14305.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AvSigVersion_x_x_1.2570000000000001</td>\n",
       "      <td>EngineVersion_1.1.14306.0</td>\n",
       "      <td>0.992248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AvSigVersion_x_x_1.2590000000000001</td>\n",
       "      <td>EngineVersion_1.1.14405.2</td>\n",
       "      <td>0.974844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AvSigVersion_x_x_1.261</td>\n",
       "      <td>EngineVersion_1.1.14500.5</td>\n",
       "      <td>0.960199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AvSigVersion_x_x_1.263</td>\n",
       "      <td>EngineVersion_1.1.14600.4</td>\n",
       "      <td>0.980869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AvSigVersion_x_x_1.265</td>\n",
       "      <td>EngineVersion_1.1.14700.5</td>\n",
       "      <td>0.980739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AvSigVersion_x_x_1.2670000000000001</td>\n",
       "      <td>EngineVersion_1.1.14800.3</td>\n",
       "      <td>0.984794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AvSigVersion_x_x_1.2690000000000001</td>\n",
       "      <td>EngineVersion_1.1.14901.4</td>\n",
       "      <td>0.987163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AvSigVersion_x_x_1.271</td>\n",
       "      <td>EngineVersion_1.1.15000.2</td>\n",
       "      <td>0.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AvSigVersion_x_x_1.273</td>\n",
       "      <td>EngineVersion_1.1.15100.1</td>\n",
       "      <td>0.984141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AvSigVersion_x_x_1.275</td>\n",
       "      <td>EngineVersion_1.1.15200.1</td>\n",
       "      <td>0.960749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>OsPlatformSubRelease_windows7</td>\n",
       "      <td>OsBuild_7601</td>\n",
       "      <td>0.994168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Census_OSSkuName_ENTERPRISE</td>\n",
       "      <td>Census_OSEdition_Enterprise</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Census_OSSkuName_ENTERPRISE_N</td>\n",
       "      <td>Census_OSEdition_EnterpriseN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Census_OSSkuName_ENTERPRISE_S</td>\n",
       "      <td>Census_OSEdition_EnterpriseS</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Census_OSSkuName_PROFESSIONAL</td>\n",
       "      <td>Census_OSEdition_Professional</td>\n",
       "      <td>0.983095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Census_OSSkuName_PROFESSIONAL_N</td>\n",
       "      <td>Census_OSEdition_ProfessionalN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Census_OSSkuName_PRO_WORKSTATION_N</td>\n",
       "      <td>Census_OSEdition_ProfessionalWorkstationN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Census_OSSkuName_DATACENTER_EVALUATION_SERVER</td>\n",
       "      <td>Census_OSEdition_ServerDatacenterEval</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Census_OSSkuName_SB_SOLUTION_SERVER</td>\n",
       "      <td>Census_OSEdition_ServerSolution</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Census_OSSkuName_STANDARD_SERVER</td>\n",
       "      <td>Census_OSEdition_ServerStandard</td>\n",
       "      <td>0.989736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Census_OSSkuName_STANDARD_EVALUATION_SERVER</td>\n",
       "      <td>Census_OSEdition_ServerStandardEval</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Census_OSUILocaleIdentifier_20</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Census_OSUILocaleIdentifier_26</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_5.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Census_OSUILocaleIdentifier_30</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_7.0</td>\n",
       "      <td>0.989521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Census_OSUILocaleIdentifier_31</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_8.0</td>\n",
       "      <td>0.977881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Census_OSUILocaleIdentifier_34</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_9.0</td>\n",
       "      <td>0.995703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Census_OSUILocaleIdentifier_35</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_10.0</td>\n",
       "      <td>0.991898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Census_OSUILocaleIdentifier_58</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_15.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Census_OSUILocaleIdentifier_64</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_17.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Census_OSUILocaleIdentifier_72</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_18.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Census_OSUILocaleIdentifier_74</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_19.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Census_OSUILocaleIdentifier_83</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_20.0</td>\n",
       "      <td>0.953455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Census_OSUILocaleIdentifier_109</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_24.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Census_OSUILocaleIdentifier_115</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_25.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Census_OSUILocaleIdentifier_119</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_26.0</td>\n",
       "      <td>0.960762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Census_OSUILocaleIdentifier_120</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_27.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Census_OSUILocaleIdentifier_123</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_28.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Census_OSUILocaleIdentifier_125</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_29.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Census_OSUILocaleIdentifier_128</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_30.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Census_OSUILocaleIdentifier_148</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_35.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Census_OSUILocaleIdentifier_160</td>\n",
       "      <td>Census_OSInstallLanguageIdentifier_39.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Field1  \\\n",
       "0                           AvSigVersion_x_x_1.199   \n",
       "1                           AvSigVersion_x_x_1.203   \n",
       "2                           AvSigVersion_x_x_1.207   \n",
       "3                           AvSigVersion_x_x_1.225   \n",
       "4                           AvSigVersion_x_x_1.227   \n",
       "5                           AvSigVersion_x_x_1.229   \n",
       "6              AvSigVersion_x_x_1.2309999999999999   \n",
       "7              AvSigVersion_x_x_1.2329999999999999   \n",
       "8                           AvSigVersion_x_x_1.235   \n",
       "9                           AvSigVersion_x_x_1.237   \n",
       "10                          AvSigVersion_x_x_1.239   \n",
       "11             AvSigVersion_x_x_1.2409999999999999   \n",
       "12             AvSigVersion_x_x_1.2429999999999999   \n",
       "13                          AvSigVersion_x_x_1.245   \n",
       "14                          AvSigVersion_x_x_1.247   \n",
       "15                          AvSigVersion_x_x_1.249   \n",
       "16                          AvSigVersion_x_x_1.251   \n",
       "17                          AvSigVersion_x_x_1.253   \n",
       "18                          AvSigVersion_x_x_1.255   \n",
       "19             AvSigVersion_x_x_1.2570000000000001   \n",
       "20             AvSigVersion_x_x_1.2590000000000001   \n",
       "21                          AvSigVersion_x_x_1.261   \n",
       "22                          AvSigVersion_x_x_1.263   \n",
       "23                          AvSigVersion_x_x_1.265   \n",
       "24             AvSigVersion_x_x_1.2670000000000001   \n",
       "25             AvSigVersion_x_x_1.2690000000000001   \n",
       "26                          AvSigVersion_x_x_1.271   \n",
       "27                          AvSigVersion_x_x_1.273   \n",
       "28                          AvSigVersion_x_x_1.275   \n",
       "29                   OsPlatformSubRelease_windows7   \n",
       "..                                             ...   \n",
       "85                     Census_OSSkuName_ENTERPRISE   \n",
       "86                   Census_OSSkuName_ENTERPRISE_N   \n",
       "87                   Census_OSSkuName_ENTERPRISE_S   \n",
       "88                   Census_OSSkuName_PROFESSIONAL   \n",
       "89                 Census_OSSkuName_PROFESSIONAL_N   \n",
       "90              Census_OSSkuName_PRO_WORKSTATION_N   \n",
       "91   Census_OSSkuName_DATACENTER_EVALUATION_SERVER   \n",
       "92             Census_OSSkuName_SB_SOLUTION_SERVER   \n",
       "93                Census_OSSkuName_STANDARD_SERVER   \n",
       "94     Census_OSSkuName_STANDARD_EVALUATION_SERVER   \n",
       "95                  Census_OSUILocaleIdentifier_20   \n",
       "96                  Census_OSUILocaleIdentifier_26   \n",
       "97                  Census_OSUILocaleIdentifier_30   \n",
       "98                  Census_OSUILocaleIdentifier_31   \n",
       "99                  Census_OSUILocaleIdentifier_34   \n",
       "100                 Census_OSUILocaleIdentifier_35   \n",
       "101                 Census_OSUILocaleIdentifier_58   \n",
       "102                 Census_OSUILocaleIdentifier_64   \n",
       "103                 Census_OSUILocaleIdentifier_72   \n",
       "104                 Census_OSUILocaleIdentifier_74   \n",
       "105                 Census_OSUILocaleIdentifier_83   \n",
       "106                Census_OSUILocaleIdentifier_109   \n",
       "107                Census_OSUILocaleIdentifier_115   \n",
       "108                Census_OSUILocaleIdentifier_119   \n",
       "109                Census_OSUILocaleIdentifier_120   \n",
       "110                Census_OSUILocaleIdentifier_123   \n",
       "111                Census_OSUILocaleIdentifier_125   \n",
       "112                Census_OSUILocaleIdentifier_128   \n",
       "113                Census_OSUILocaleIdentifier_148   \n",
       "114                Census_OSUILocaleIdentifier_160   \n",
       "\n",
       "                                        Field2  Correlation  \n",
       "0                    EngineVersion_1.1.11701.0     1.000000  \n",
       "1                    EngineVersion_1.1.11903.0     1.000000  \n",
       "2                    EngineVersion_1.1.12101.0     1.000000  \n",
       "3                    EngineVersion_1.1.12902.0     0.970322  \n",
       "4                    EngineVersion_1.1.13000.0     0.969724  \n",
       "5                    EngineVersion_1.1.13103.0     0.990140  \n",
       "6                    EngineVersion_1.1.13202.0     1.000000  \n",
       "7                    EngineVersion_1.1.13303.0     0.994483  \n",
       "8                    EngineVersion_1.1.13407.0     1.000000  \n",
       "9                    EngineVersion_1.1.13504.0     1.000000  \n",
       "10                   EngineVersion_1.1.13601.0     0.992149  \n",
       "11                   EngineVersion_1.1.13701.0     0.989063  \n",
       "12                   EngineVersion_1.1.13704.0     1.000000  \n",
       "13                   EngineVersion_1.1.13804.0     0.987246  \n",
       "14                   EngineVersion_1.1.13903.0     0.994229  \n",
       "15                   EngineVersion_1.1.14003.0     0.993831  \n",
       "16                   EngineVersion_1.1.14104.0     0.996961  \n",
       "17                   EngineVersion_1.1.14202.0     0.980109  \n",
       "18                   EngineVersion_1.1.14305.0     1.000000  \n",
       "19                   EngineVersion_1.1.14306.0     0.992248  \n",
       "20                   EngineVersion_1.1.14405.2     0.974844  \n",
       "21                   EngineVersion_1.1.14500.5     0.960199  \n",
       "22                   EngineVersion_1.1.14600.4     0.980869  \n",
       "23                   EngineVersion_1.1.14700.5     0.980739  \n",
       "24                   EngineVersion_1.1.14800.3     0.984794  \n",
       "25                   EngineVersion_1.1.14901.4     0.987163  \n",
       "26                   EngineVersion_1.1.15000.2     0.985600  \n",
       "27                   EngineVersion_1.1.15100.1     0.984141  \n",
       "28                   EngineVersion_1.1.15200.1     0.960749  \n",
       "29                                OsBuild_7601     0.994168  \n",
       "..                                         ...          ...  \n",
       "85                 Census_OSEdition_Enterprise     1.000000  \n",
       "86                Census_OSEdition_EnterpriseN     1.000000  \n",
       "87                Census_OSEdition_EnterpriseS     1.000000  \n",
       "88               Census_OSEdition_Professional     0.983095  \n",
       "89              Census_OSEdition_ProfessionalN     1.000000  \n",
       "90   Census_OSEdition_ProfessionalWorkstationN     1.000000  \n",
       "91       Census_OSEdition_ServerDatacenterEval     1.000000  \n",
       "92             Census_OSEdition_ServerSolution     1.000000  \n",
       "93             Census_OSEdition_ServerStandard     0.989736  \n",
       "94         Census_OSEdition_ServerStandardEval     1.000000  \n",
       "95      Census_OSInstallLanguageIdentifier_3.0     1.000000  \n",
       "96      Census_OSInstallLanguageIdentifier_5.0     1.000000  \n",
       "97      Census_OSInstallLanguageIdentifier_7.0     0.989521  \n",
       "98      Census_OSInstallLanguageIdentifier_8.0     0.977881  \n",
       "99      Census_OSInstallLanguageIdentifier_9.0     0.995703  \n",
       "100    Census_OSInstallLanguageIdentifier_10.0     0.991898  \n",
       "101    Census_OSInstallLanguageIdentifier_15.0     1.000000  \n",
       "102    Census_OSInstallLanguageIdentifier_17.0     1.000000  \n",
       "103    Census_OSInstallLanguageIdentifier_18.0     1.000000  \n",
       "104    Census_OSInstallLanguageIdentifier_19.0     1.000000  \n",
       "105    Census_OSInstallLanguageIdentifier_20.0     0.953455  \n",
       "106    Census_OSInstallLanguageIdentifier_24.0     1.000000  \n",
       "107    Census_OSInstallLanguageIdentifier_25.0     1.000000  \n",
       "108    Census_OSInstallLanguageIdentifier_26.0     0.960762  \n",
       "109    Census_OSInstallLanguageIdentifier_27.0     1.000000  \n",
       "110    Census_OSInstallLanguageIdentifier_28.0     1.000000  \n",
       "111    Census_OSInstallLanguageIdentifier_29.0     1.000000  \n",
       "112    Census_OSInstallLanguageIdentifier_30.0     1.000000  \n",
       "113    Census_OSInstallLanguageIdentifier_35.0     1.000000  \n",
       "114    Census_OSInstallLanguageIdentifier_39.0     1.000000  \n",
       "\n",
       "[115 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping the following  96  highly correlated fields.\n",
      "\r\n",
      "*********Before: Dropping Highly Correlated Fields*************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66585 entries, 0 to 66584\n",
      "Columns: 404 entries, Census_IsSecureBootEnabled to Census_ActivationChannel_Volume:MAK\n",
      "dtypes: float64(9), int64(1), uint8(394)\n",
      "memory usage: 30.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "*********After: Dropping Highly Correlated Fields**************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66585 entries, 0 to 66584\n",
      "Columns: 308 entries, Census_IsSecureBootEnabled to Census_ActivationChannel_Volume:MAK\n",
      "dtypes: float64(9), int64(1), uint8(298)\n",
      "memory usage: 24.0 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get data and create a model\n",
    "subMalware = pd.read_csv(\"data/malware.subsample.csv\")\n",
    "cols_categorical, cols_numerical, cols_booleans, cols_categorical_large = load_column_array(subMalware.columns)\n",
    "subMalware[cols_categorical] = subMalware[cols_categorical].astype(object)\n",
    "subMalware[cols_categorical_large] = subMalware[cols_categorical_large].astype(object)\n",
    "\n",
    "model_data = pd.concat(\n",
    "    (    \n",
    "        subMalware[cols_booleans],\n",
    "        subMalware[cols_numerical],\n",
    "        get_one_hot_encodings(subMalware, cols_categorical),\n",
    "#        get_one_hot_encodings(subMalware, cols_categorical_large)\n",
    "    ), axis = 1)\n",
    "\n",
    "response_data = subMalware[\"HasDetections\"]\n",
    "# print(response_data1.shape)\n",
    "# print(model_data.shape)\n",
    "# To REduce the Overall Model\n",
    "model_data = reduce_features(model_data, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative Variance Explained')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scale Data\n",
    "X = StandardScaler().fit_transform(model_data)\n",
    "\n",
    "pca = PCA(n_components=300)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# pca_expl_var = pca.explained_variance_ratio_\n",
    "pca_sum = np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4 ) * 100 )\n",
    "plt.plot(pca_sum)\n",
    "plt.xlabel('# of Detections')\n",
    "plt.ylabel('Cumulative Variance Explained')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for Metrics - Needs to be in Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def getSummaryMetrics(test, yhat, shortDesc, iter_num = 0):\n",
    "    print('\\n' + shortDesc + '\\n')\n",
    "    conf = mt.confusion_matrix(test,yhat)\n",
    "    acc = mt.accuracy_score(test,yhat)\n",
    "    rocauc = mt.roc_auc_score(test,yhat)    \n",
    "    cm = mt.classification_report(test,yhat)\n",
    "    mae = mt.mean_absolute_error(test,yhat)\n",
    "    cfraw = mt.confusion_matrix(y_test,yhat)\n",
    "\n",
    "    print('Confusion Matrix Raw:\\n',cfraw)\n",
    "    print('Confusion Matrix:\\n',cm)\n",
    "    print('AUC:',rocauc)\n",
    "    print('MAE:', mae)\n",
    "    print('Accuracy:', acc)\n",
    "    rmse = sqrt(mean_squared_error(test,yhat))\n",
    "    print('RMSE: ', rmse)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test,yhat)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     df = pd.DataFrame(\n",
    "    df = {\n",
    "            \"shortDesc\":shortDesc,\n",
    "            \"test_num\":iter_num,\n",
    "            \"rocauc\":rocauc,\n",
    "            \"mae\":mae,\n",
    "            \"accuracy\":acc,\n",
    "            \"rmse\":rmse\n",
    "        }\n",
    "#     )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "    \n",
    "test_result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - By Grant Handy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to ensure our X/Y values, along with our Testing Splits are Accurage for the following Code.  Additionaly, the standardard scaler was applied to the Model Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66585, 308)\n",
      "(66585,)\n",
      "(6658, 308)\n",
      "(6659, 308)\n",
      "(6658,)\n",
      "(6659,)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#Seperate train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scale the Data Using StandardScaler If Needed\n",
    "# Uncomment if you dont run PCA\n",
    "# X = StandardScaler().fit_transform(model_data)\n",
    "\n",
    "\n",
    "# Set CV For Entire Dataset Below\n",
    "cv = 2\n",
    "\n",
    "# Set Variables\n",
    "X = model_data.values\n",
    "y = response_data.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, train_size=0.1, test_size=0.1, random_state=42)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the team is testing the test the Pipleine using a standard Scaler and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('normalizer', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('clf',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('normalizer', StandardScaler()), #Step1 - normalize data\n",
    "    ('clf', PCA(n_components=100)) #step2 - classifier\n",
    "])\n",
    "pipeline.steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.29166317, 0.17506027, 0.19378114]), 'score_time': array([0.03999901, 0.02204967, 0.02373672]), 'test_score': array([-347.31318316, -354.73557725, -342.94949247]), 'train_score': array([-329.78418305, -328.46367988, -333.47613632])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(pipeline, X_train, y_train)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Pipeline for \"Has Detections\" with Multiple Machine Learning Algoriths\n",
    "The following finalizes the pipleline and analyzes LogisticRegression, SVC, K-Nearest Neighbors, Decision Tree, Random Forest, and Gradient Boosting.  The purpose of this code is to analyze the best model fit and do further analysis and tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.8895676930745443\n",
      "fit_time  std  0.11399864405292638\n",
      "score_time  mean  0.004623889923095703\n",
      "score_time  std  0.0007720758829405713\n",
      "test_score  mean  0.6221116564965145\n",
      "test_score  std  0.01380289901925498\n",
      "train_score  mean  0.6657406900740473\n",
      "train_score  std  0.002143818440893808\n",
      "---------------------------------\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  8.23613444964091\n",
      "fit_time  std  0.7458004970300693\n",
      "score_time  mean  3.8431830406188965\n",
      "score_time  std  0.1668540610557466\n",
      "test_score  mean  0.6093433451477615\n",
      "test_score  std  0.007171644251928657\n",
      "train_score  mean  0.7152302692925918\n",
      "train_score  std  0.005531057080058874\n",
      "---------------------------------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "-----------------------------------\n",
      "fit_time  mean  0.1340609391530355\n",
      "fit_time  std  0.02957321548095213\n",
      "score_time  mean  5.124529679616292\n",
      "score_time  std  1.2829629680357366\n",
      "test_score  mean  0.5480623255071205\n",
      "test_score  std  0.001980469280134345\n",
      "train_score  mean  0.7165820096720781\n",
      "train_score  std  0.005577681390644208\n",
      "---------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "-----------------------------------\n",
      "fit_time  mean  0.14983812967936197\n",
      "fit_time  std  0.017761377186476347\n",
      "score_time  mean  0.005400260289510091\n",
      "score_time  std  0.0004049063664012533\n",
      "test_score  mean  0.5576749124067736\n",
      "test_score  std  0.0007971189813787583\n",
      "train_score  mean  0.9988735186633368\n",
      "train_score  std  0.00018406140539923958\n",
      "---------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  0.13779266675313315\n",
      "fit_time  std  0.003351014852028459\n",
      "score_time  mean  0.010353565216064453\n",
      "score_time  std  7.372674535579663e-05\n",
      "test_score  mean  0.5827559420619357\n",
      "test_score  std  0.007734158349750302\n",
      "train_score  mean  0.9828778254713985\n",
      "train_score  std  0.0010227974356992286\n",
      "---------------------------------\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "-----------------------------------\n",
      "fit_time  mean  4.357675870259603\n",
      "fit_time  std  0.3912519271552897\n",
      "score_time  mean  0.009798367818196615\n",
      "score_time  std  0.0014371403690602792\n",
      "test_score  mean  0.6294688108568235\n",
      "test_score  std  0.003920314798629648\n",
      "train_score  mean  0.6816615112413111\n",
      "train_score  std  0.005741800826688346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clfs = []\n",
    "clfs.append(LogisticRegression())\n",
    "clfs.append(SVC())\n",
    "clfs.append(KNeighborsClassifier(n_neighbors=5))\n",
    "clfs.append(DecisionTreeClassifier())\n",
    "clfs.append(RandomForestClassifier())\n",
    "clfs.append(GradientBoostingClassifier())\n",
    "# clfs.append(XGBClassifier())\n",
    "\n",
    "for classifier in clfs:\n",
    "    pipeline.set_params(clf = classifier)\n",
    "    scores = cross_validate(pipeline, X_train, y_train)\n",
    "    print('---------------------------------')\n",
    "    print(str(classifier))\n",
    "    print('-----------------------------------')\n",
    "    for key, values in scores.items():\n",
    "            print(key,' mean ', values.mean())\n",
    "            print(key,' std ', values.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradiant Boosting had the Highest Test Score with a 62.8% Accuracy Rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/all-things-ai/in-depth-parameter-tuning-for-random-forest-d67bb7e920d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optmized Random Forest Using GridSearch and RandomizedSearch for \"Has Detections\"\n",
    "The following Random Forest classifier was used to determine what an optimal accuracy rate.  In the code below, two different types of searches were performed, Grid Search and Randomized Search.  For each model, the team identified multiple settings for Max Depth, Maximum number of Features, Minimum Sample Splits, whether or not to Bootstrap, and the splitting Criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - fold cross validation:\n",
      "\n",
      "RandomizedSearchCV took 448.12 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.628 (std: 0.000)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 296, 'min_samples_split': 6}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.628 (std: 0.003)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 263, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.626 (std: 0.003)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': 3, 'max_features': 257, 'min_samples_split': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "print(cv,\"- fold cross validation:\\n\")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(100, 300),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=cv)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [50, 100, 300],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=cv)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model that peformed was the Grid Search without using the split crieria of entropy, maximium depth of 3, max features of 50 and a minimium samples split of 10.  The next step is to rerun the exact model to understand which features are driving gthe top model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a regression estimator with best parameters for cross validation\n",
    "rfClass = RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=3,\n",
    "                                       max_features='auto', max_leaf_nodes=None,\n",
    "                                       min_samples_split=10,n_estimators=500, \n",
    "                                       verbose=0)\n",
    "\n",
    "#Fit the model using all of the scaled training data\n",
    "rfClass.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model's coefficient weights and feature names into a dataframe sorted by weights\n",
    "weights = regEstimator.feature_importances_.ravel()\n",
    "feature_names = model_data.columns.values\n",
    "linreg_ft_imp_df = pd.DataFrame({'feature_names':feature_names, 'weights':weights, 'absolute_weights': np.abs(weights)})\n",
    "linreg_ft_imp_df.sort_values(by='absolute_weights', inplace=True, ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine categorical variables of interest  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Plot the model's feature importances\n",
    "# REFERENCE:  Eric Larson, https://github.com/eclarson/DataMiningNotebooks\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "wt_plt_df = linreg_ft_imp_df.head(75)\n",
    "\n",
    "weights = pd.Series(wt_plt_df['weights'].values,index=wt_plt_df['feature_names'])\n",
    "ax = weights.plot(kind='bar', figsize=(20,8))\n",
    "\n",
    "ax.set_title(\"Top Feature Correlations\")\n",
    "ax.set_ylabel(\"Coefficient Magnitude\\n(z-score)\")\n",
    "ax.set_xlabel(\"Feature Names\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble with Adaboost, Random Forest, Gradiant Boosting for \"Has Detections\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "import numpy as np\n",
    "\n",
    "clf1 = LogisticRegression(random_state=2)\n",
    "clf2 = RandomForestClassifier(random_state=2)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf5 = DecisionTreeClassifier()\n",
    "clf6 = GradientBoostingClassifier()\n",
    "clf7 = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "print(cv,\"- fold cross validation:\\n\")\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'KNN', 'Decision Tree', 'Gradiant Boosting', 'Adaboost']\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_train, y_train, \n",
    "                                              cv=cv, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codes fits 7 different models into a  Ensemble Voting Classfier to determine the overall score.  The default weighting systems uses \"Hard\" which the simple majority wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "print(cv,\"- fold cross validation:\\n\")\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4, clf5, clf6, clf7], weights=[1,1,1,1,1,1,1])\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'KNN', 'Decision Tree', 'Gradiant Boosting', 'Adaboost', 'Ensemble']\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, eclf], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_train, y_train, \n",
    "                                              cv=cv, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "    \n",
    "    voting='soft'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Ensemble Vote Classifer is using the Soft Voting System which which predicts whether the machine \"Has Detections\" based on the sums of the predicted probabilities.  SKLearn recommended this approach.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "print(cv,\"- fold cross validation:\\n\")\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4, clf5, clf6, clf7], voting='soft', weights=[1,1,1,1,1,1,1])\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'KNN', 'Decision Tree', 'Gradiant Boosting', 'Adaboost', 'Ensemble']\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6, clf7, eclf], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X_train, y_train, \n",
    "                                              cv=cv, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Gradiant Boosting Optimizatoin using \"Has Detections\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still working on Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': [0.1, 0.05, 0.02, 0.01], 'max_depth': [4, 6, 8], 'min_samples_leaf': [20, 50, 100, 150]}\n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  4.8min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gb_grid_params = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_leaf': [20, 50,100,150],\n",
    "              #'max_features': [1.0, 0.3, 0.1] \n",
    "              }\n",
    "print(gb_grid_params)\n",
    "\n",
    "gb_gs = GradientBoostingClassifier(n_estimators = 600)\n",
    "\n",
    "clf = GridSearchCV(gb_gs,\n",
    "                   gb_grid_params,\n",
    "                   cv=2,\n",
    "                   scoring='roc_auc',\n",
    "                   verbose = 3, \n",
    "                   n_jobs=10);\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validation.cross_val_score(gb,\n",
    "                                          all_data, target,\n",
    "                                          scoring=\"roc_auc\",\n",
    "                                          n_jobs=6,\n",
    "                                          cv=3);\n",
    "\"Accuracy: %0.5f (+/- %0.5f)\"%(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Grant's Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc\n",
    "# false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "# roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "# roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for estimator in n_estimators:\n",
    "#    rf = RandomForestClassifier(n_estimators=estimator, n_jobs=-1)\n",
    "#    rf.fit(X_train, y_train)\n",
    "#    train_pred = rf.predict(X_train)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    train_results.append(roc_auc)\n",
    "#    y_pred = rf.predict(X_test)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    test_results.append(roc_auc)\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel('n_estimators')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for max_depth in max_depths:\n",
    "#    rf = RandomForestClassifier(max_depth=max_depth, n_jobs=-1)\n",
    "#    rf.fit(X_train, y_train)\n",
    "#    train_pred = rf.predict(X_train)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    train_results.append(roc_auc)\n",
    "#    y_pred = rf.predict(X_test)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    test_results.append(roc_auc)\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel('Tree depth')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for min_samples_split in min_samples_splits:\n",
    "#    rf = RandomForestClassifier(min_samples_split=min_samples_split)\n",
    "#    rf.fit(X_train, y_train)\n",
    "#    train_pred = rf.predict(X_train)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    train_results.append(roc_auc)\n",
    "#    y_pred = rf.predict(X_test)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    test_results.append(roc_auc)\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(min_samples_splits, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel('Min samples split')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for min_samples_leaf in min_samples_leafs:\n",
    "#    rf = RandomForestClassifier(min_samples_leaf=min_samples_leaf)\n",
    "#    rf.fit(X_train, y_train)\n",
    "#    train_pred = rf.predict(X_train)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    train_results.append(roc_auc)\n",
    "#    y_pred = rf.predict(X_test)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    test_results.append(roc_auc)\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(min_samples_leafs, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(min_samples_leafs, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel('Min samples leaf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max_features = list(range(1,X.shape[1]))\n",
    "# train_results = []\n",
    "# test_results = []\n",
    "# for max_feature in max_features:\n",
    "#    rf = RandomForestClassifier(max_features=max_feature)\n",
    "#    rf.fit(X_train, y_train)\n",
    "#    train_pred = rf.predict(X_train)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    train_results.append(roc_auc)\n",
    "#    y_pred = rf.predict(X_test)\n",
    "#    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "#    test_results.append(roc_auc)\n",
    "# from matplotlib.legend_handler import HandlerLine2D\n",
    "# line1, = plt.plot(max_features, train_results, 'b', label=\"Train AUC\")\n",
    "# line2, = plt.plot(max_features, test_results, 'r', label=\"Test AUC\")\n",
    "# plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "# plt.ylabel('AUC score')\n",
    "# plt.xlabel('Max features')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
